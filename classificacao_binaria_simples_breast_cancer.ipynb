{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classificacao_binaria_breast_cancer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMPEiYSCc4BML1OBmUdBFkN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itimes-digital/deep-learning-estudo/blob/main/classificacao_binaria_simples_breast_cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ip00_xXzIcE"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaRAemgJMDAN",
        "outputId": "1998a649-fad6-40f5-960f-85629e22ae98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "previsores = pd.read_csv(\"https://raw.githubusercontent.com/itimes-digital/deep-learning-estudo/main/dataset/entradas_breast.csv\", sep=\",\")\n",
        "previsores.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave_points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave_points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave_points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1095.0000</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8589.0</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3398.0</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>186.0000</td>\n",
              "      <td>275.0000</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4585.0</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>243.0000</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1156.0000</td>\n",
              "      <td>3445.0</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>173.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>198.0000</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5438.0</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>205.0000</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    radius_mean   texture_mean  ...   symmetry_worst   fractal_dimension_worst\n",
              "0         17.99          10.38  ...           0.4601                   0.11890\n",
              "1         20.57          17.77  ...         275.0000                   0.08902\n",
              "2         19.69          21.25  ...           0.3613                   0.08758\n",
              "3         11.42          20.38  ...           0.6638                 173.00000\n",
              "4         20.29          14.34  ...           0.2364                   0.07678\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zGlSapRMLyK",
        "outputId": "3865f791-3756-4a3d-9aaf-87fb3771c8a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        }
      },
      "source": [
        "previsores.info()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 30 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0    radius_mean              569 non-null    float64\n",
            " 1    texture_mean             569 non-null    float64\n",
            " 2    perimeter_mean           569 non-null    float64\n",
            " 3    area_mean                569 non-null    float64\n",
            " 4    smoothness_mean          569 non-null    float64\n",
            " 5    compactness_mean         569 non-null    float64\n",
            " 6    concavity_mean           569 non-null    float64\n",
            " 7   concave_points_mean       569 non-null    float64\n",
            " 8    symmetry_mean            569 non-null    float64\n",
            " 9    fractal_dimension_mean   569 non-null    float64\n",
            " 10   radius_se                569 non-null    float64\n",
            " 11   texture_se               569 non-null    float64\n",
            " 12   perimeter_se             569 non-null    float64\n",
            " 13   area_se                  569 non-null    float64\n",
            " 14   smoothness_se            569 non-null    float64\n",
            " 15   compactness_se           569 non-null    float64\n",
            " 16   concavity_se             569 non-null    float64\n",
            " 17   concave_points_se        569 non-null    float64\n",
            " 18   symmetry_se              569 non-null    float64\n",
            " 19   fractal_dimension_se     569 non-null    float64\n",
            " 20   radius_worst             569 non-null    float64\n",
            " 21   texture_worst            569 non-null    float64\n",
            " 22   perimeter_worst          569 non-null    float64\n",
            " 23   area_worst               569 non-null    float64\n",
            " 24   smoothness_worst         569 non-null    float64\n",
            " 25   compactness_worst        569 non-null    float64\n",
            " 26   concavity_worst          569 non-null    float64\n",
            " 27   concave_points_worst     569 non-null    float64\n",
            " 28   symmetry_worst           569 non-null    float64\n",
            " 29   fractal_dimension_worst  569 non-null    float64\n",
            "dtypes: float64(30)\n",
            "memory usage: 133.5 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3u7mliUMish",
        "outputId": "bb6062a7-f20b-46fb-e343-de5d70e53c41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "classe = pd.read_csv(\"https://raw.githubusercontent.com/itimes-digital/deep-learning-estudo/main/dataset/saidas_breast.csv\")\n",
        "classe.info()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype\n",
            "---  ------  --------------  -----\n",
            " 0   0       569 non-null    int64\n",
            "dtypes: int64(1)\n",
            "memory usage: 4.6 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxUoFl1MciQa"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# previsores_treinamento = x_train\n",
        "# previsores_teste = x_test\n",
        "# classe_treinamento = y_train\n",
        "# classe_teste = y_test\n",
        "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores, \n",
        "                                                                                              classe, \n",
        "                                                                                              test_size = 0.25)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpMUF67KdXBT",
        "outputId": "7c63a897-8524-4768-882e-56b42979e349",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "previsores_treinamento.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(426, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm6KvUM3dZl3",
        "outputId": "596808c3-f969-4092-f47d-0db8cc95e793",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "previsores_teste.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(143, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUik7a1tdiKv",
        "outputId": "9032fdd9-c06c-456e-ef33-f3c99acffd61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "classe_treinamento.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(426, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaoe6MiZdl5_",
        "outputId": "a1508e31-b899-441a-ef66-1449a930da96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "classe_teste.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(143, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g6n8WsidoT3"
      },
      "source": [
        "import keras"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RexXf9H_eAV8"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtgFqY6pfIcE"
      },
      "source": [
        "Definição do números de neurônios por camada:\n",
        "\n",
        "(numero de entrada + numero de saídas esperada) / 2 = número de units na camada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O4W7keffmao",
        "outputId": "5e25e5ca-028e-4eb1-c155-f8fc58d30f36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Medida base para definir a quantidade de neurônios na camada.\n",
        "# Como a classificação é binária, a resposta será 0 ou 1, portanto, uma saída.\n",
        "quantSaidaEsperada = 1\n",
        "units = (previsores.columns.size + quantSaidaEsperada) / 2\n",
        "units = np.round(units)\n",
        "units"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjZEHAGLek7e"
      },
      "source": [
        "# input_dim define a quantidade de neurônios para a camada de entrada.\n",
        "classificador = Sequential()\n",
        "classificador.add(Dense(units=units, # define a quantidade de neurônios da primeira camada oculta \n",
        "                        activation='relu', \n",
        "                        kernel_initializer='random_uniform', \n",
        "                        input_dim=30))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFJRJl67iNxZ"
      },
      "source": [
        "# Definindo a camada de saída\n",
        "# Como é um classificador binário para 0 ou 1\n",
        "# A quantidade de neurônio é 1\n",
        "classificador.add(Dense(units=1, activation=\"sigmoid\"))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJd_5c4Ii5ol",
        "outputId": "4c658580-7c43-45c9-cbe1-3292f94c3eec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# para classificação binária deve usar binary_crossentropy\n",
        "# para classificação com mais de duas classes deve usar categorical_crossentropy\n",
        "classificador.compile(optimizer='adam', \n",
        "                      loss='binary_crossentropy',\n",
        "                      metrics=['binary_accuracy'])\n",
        "classificador.fit(previsores_treinamento, \n",
        "                  classe_treinamento,\n",
        "                  batch_size=10, # Atualização de pesos a cada 10 registros por épocas\n",
        "                  epochs=100)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 18.5102 - binary_accuracy: 0.5282\n",
            "Epoch 2/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 1.7868 - binary_accuracy: 0.7089\n",
            "Epoch 3/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.8952 - binary_accuracy: 0.7629\n",
            "Epoch 4/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.8357 - binary_accuracy: 0.7887\n",
            "Epoch 5/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.7348 - binary_accuracy: 0.7700\n",
            "Epoch 6/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4713 - binary_accuracy: 0.8357\n",
            "Epoch 7/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3991 - binary_accuracy: 0.8592\n",
            "Epoch 8/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4204 - binary_accuracy: 0.8662\n",
            "Epoch 9/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4044 - binary_accuracy: 0.8638\n",
            "Epoch 10/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3072 - binary_accuracy: 0.8779\n",
            "Epoch 11/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4322 - binary_accuracy: 0.8427\n",
            "Epoch 12/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3248 - binary_accuracy: 0.8991\n",
            "Epoch 13/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3875 - binary_accuracy: 0.8427\n",
            "Epoch 14/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2692 - binary_accuracy: 0.8732\n",
            "Epoch 15/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3233 - binary_accuracy: 0.8779\n",
            "Epoch 16/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2775 - binary_accuracy: 0.9108\n",
            "Epoch 17/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2389 - binary_accuracy: 0.9014\n",
            "Epoch 18/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2849 - binary_accuracy: 0.8897\n",
            "Epoch 19/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3166 - binary_accuracy: 0.8897\n",
            "Epoch 20/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3209 - binary_accuracy: 0.8991\n",
            "Epoch 21/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.6702 - binary_accuracy: 0.8286\n",
            "Epoch 22/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5174 - binary_accuracy: 0.8333\n",
            "Epoch 23/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4493 - binary_accuracy: 0.8732\n",
            "Epoch 24/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3711 - binary_accuracy: 0.8873\n",
            "Epoch 25/100\n",
            "43/43 [==============================] - 0s 998us/step - loss: 0.4586 - binary_accuracy: 0.8756\n",
            "Epoch 26/100\n",
            "43/43 [==============================] - 0s 996us/step - loss: 0.4429 - binary_accuracy: 0.8803\n",
            "Epoch 27/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5730 - binary_accuracy: 0.8709\n",
            "Epoch 28/100\n",
            "43/43 [==============================] - 0s 989us/step - loss: 0.3334 - binary_accuracy: 0.8944\n",
            "Epoch 29/100\n",
            "43/43 [==============================] - 0s 956us/step - loss: 0.4011 - binary_accuracy: 0.8732\n",
            "Epoch 30/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3307 - binary_accuracy: 0.8897\n",
            "Epoch 31/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2733 - binary_accuracy: 0.9296\n",
            "Epoch 32/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3336 - binary_accuracy: 0.8897\n",
            "Epoch 33/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2588 - binary_accuracy: 0.9085\n",
            "Epoch 34/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3428 - binary_accuracy: 0.9061\n",
            "Epoch 35/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2962 - binary_accuracy: 0.9038\n",
            "Epoch 36/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3487 - binary_accuracy: 0.9108\n",
            "Epoch 37/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3897 - binary_accuracy: 0.8897\n",
            "Epoch 38/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4332 - binary_accuracy: 0.8662\n",
            "Epoch 39/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4316 - binary_accuracy: 0.8732\n",
            "Epoch 40/100\n",
            "43/43 [==============================] - 0s 995us/step - loss: 0.8494 - binary_accuracy: 0.8286\n",
            "Epoch 41/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5925 - binary_accuracy: 0.8826\n",
            "Epoch 42/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3908 - binary_accuracy: 0.8873\n",
            "Epoch 43/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5582 - binary_accuracy: 0.8685\n",
            "Epoch 44/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3143 - binary_accuracy: 0.9014\n",
            "Epoch 45/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5601 - binary_accuracy: 0.8545\n",
            "Epoch 46/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4004 - binary_accuracy: 0.9038\n",
            "Epoch 47/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2501 - binary_accuracy: 0.9131\n",
            "Epoch 48/100\n",
            "43/43 [==============================] - 0s 999us/step - loss: 0.2718 - binary_accuracy: 0.9131\n",
            "Epoch 49/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2526 - binary_accuracy: 0.9155\n",
            "Epoch 50/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2340 - binary_accuracy: 0.9249\n",
            "Epoch 51/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3142 - binary_accuracy: 0.9225\n",
            "Epoch 52/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3394 - binary_accuracy: 0.8873\n",
            "Epoch 53/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2716 - binary_accuracy: 0.9296\n",
            "Epoch 54/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2685 - binary_accuracy: 0.9131\n",
            "Epoch 55/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4085 - binary_accuracy: 0.8873\n",
            "Epoch 56/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2352 - binary_accuracy: 0.9202\n",
            "Epoch 57/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3922 - binary_accuracy: 0.8803\n",
            "Epoch 58/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3184 - binary_accuracy: 0.9038\n",
            "Epoch 59/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2326 - binary_accuracy: 0.9272\n",
            "Epoch 60/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2549 - binary_accuracy: 0.9014\n",
            "Epoch 61/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2909 - binary_accuracy: 0.9131\n",
            "Epoch 62/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5573 - binary_accuracy: 0.8850\n",
            "Epoch 63/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2109 - binary_accuracy: 0.9366\n",
            "Epoch 64/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1716 - binary_accuracy: 0.9390\n",
            "Epoch 65/100\n",
            "43/43 [==============================] - 0s 993us/step - loss: 0.2487 - binary_accuracy: 0.9155\n",
            "Epoch 66/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2311 - binary_accuracy: 0.9343\n",
            "Epoch 67/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3012 - binary_accuracy: 0.8920\n",
            "Epoch 68/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4104 - binary_accuracy: 0.8709\n",
            "Epoch 69/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2935 - binary_accuracy: 0.9038\n",
            "Epoch 70/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.7250 - binary_accuracy: 0.8615\n",
            "Epoch 71/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2390 - binary_accuracy: 0.9272\n",
            "Epoch 72/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2502 - binary_accuracy: 0.9178\n",
            "Epoch 73/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1877 - binary_accuracy: 0.9319\n",
            "Epoch 74/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3928 - binary_accuracy: 0.8850\n",
            "Epoch 75/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2803 - binary_accuracy: 0.9202\n",
            "Epoch 76/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3860 - binary_accuracy: 0.9085\n",
            "Epoch 77/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3938 - binary_accuracy: 0.8944\n",
            "Epoch 78/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1793 - binary_accuracy: 0.9366\n",
            "Epoch 79/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2004 - binary_accuracy: 0.9296\n",
            "Epoch 80/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1893 - binary_accuracy: 0.9437\n",
            "Epoch 81/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1875 - binary_accuracy: 0.9296\n",
            "Epoch 82/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2539 - binary_accuracy: 0.9178\n",
            "Epoch 83/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4224 - binary_accuracy: 0.8944\n",
            "Epoch 84/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2906 - binary_accuracy: 0.9108\n",
            "Epoch 85/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2470 - binary_accuracy: 0.9272\n",
            "Epoch 86/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2567 - binary_accuracy: 0.9296\n",
            "Epoch 87/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.6132 - binary_accuracy: 0.8756\n",
            "Epoch 88/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4335 - binary_accuracy: 0.8991\n",
            "Epoch 89/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2136 - binary_accuracy: 0.9319\n",
            "Epoch 90/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3921 - binary_accuracy: 0.9038\n",
            "Epoch 91/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3070 - binary_accuracy: 0.9085\n",
            "Epoch 92/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2041 - binary_accuracy: 0.9366\n",
            "Epoch 93/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2469 - binary_accuracy: 0.9085\n",
            "Epoch 94/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2893 - binary_accuracy: 0.9038\n",
            "Epoch 95/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2025 - binary_accuracy: 0.9343\n",
            "Epoch 96/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2284 - binary_accuracy: 0.9225\n",
            "Epoch 97/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1706 - binary_accuracy: 0.9272\n",
            "Epoch 98/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2775 - binary_accuracy: 0.9202\n",
            "Epoch 99/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2203 - binary_accuracy: 0.9202\n",
            "Epoch 100/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3218 - binary_accuracy: 0.9085\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc8ffad1518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHdpaZ2CmudR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}