{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classificacao_binaria_breast_cancer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOila5NtQ46aOgpDEvTeNc2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itimes-digital/deep-learning-estudo/blob/main/classificacao_binaria_simples_breast_cancer_validacao_cruzada.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ip00_xXzIcE"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaRAemgJMDAN",
        "outputId": "28f6bcc6-943b-4234-ff78-858b07243158",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "previsores = pd.read_csv(\"https://raw.githubusercontent.com/itimes-digital/deep-learning-estudo/main/dataset/entradas_breast.csv\", sep=\",\")\n",
        "previsores.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave_points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave_points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave_points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1095.0000</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8589.0</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3398.0</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>186.0000</td>\n",
              "      <td>275.0000</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4585.0</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>243.0000</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1156.0000</td>\n",
              "      <td>3445.0</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>173.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>198.0000</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5438.0</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>205.0000</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    radius_mean   texture_mean  ...   symmetry_worst   fractal_dimension_worst\n",
              "0         17.99          10.38  ...           0.4601                   0.11890\n",
              "1         20.57          17.77  ...         275.0000                   0.08902\n",
              "2         19.69          21.25  ...           0.3613                   0.08758\n",
              "3         11.42          20.38  ...           0.6638                 173.00000\n",
              "4         20.29          14.34  ...           0.2364                   0.07678\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zGlSapRMLyK",
        "outputId": "b79df8dc-2ade-4a3f-d72c-06311a39e8a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        }
      },
      "source": [
        "previsores.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 30 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0    radius_mean              569 non-null    float64\n",
            " 1    texture_mean             569 non-null    float64\n",
            " 2    perimeter_mean           569 non-null    float64\n",
            " 3    area_mean                569 non-null    float64\n",
            " 4    smoothness_mean          569 non-null    float64\n",
            " 5    compactness_mean         569 non-null    float64\n",
            " 6    concavity_mean           569 non-null    float64\n",
            " 7   concave_points_mean       569 non-null    float64\n",
            " 8    symmetry_mean            569 non-null    float64\n",
            " 9    fractal_dimension_mean   569 non-null    float64\n",
            " 10   radius_se                569 non-null    float64\n",
            " 11   texture_se               569 non-null    float64\n",
            " 12   perimeter_se             569 non-null    float64\n",
            " 13   area_se                  569 non-null    float64\n",
            " 14   smoothness_se            569 non-null    float64\n",
            " 15   compactness_se           569 non-null    float64\n",
            " 16   concavity_se             569 non-null    float64\n",
            " 17   concave_points_se        569 non-null    float64\n",
            " 18   symmetry_se              569 non-null    float64\n",
            " 19   fractal_dimension_se     569 non-null    float64\n",
            " 20   radius_worst             569 non-null    float64\n",
            " 21   texture_worst            569 non-null    float64\n",
            " 22   perimeter_worst          569 non-null    float64\n",
            " 23   area_worst               569 non-null    float64\n",
            " 24   smoothness_worst         569 non-null    float64\n",
            " 25   compactness_worst        569 non-null    float64\n",
            " 26   concavity_worst          569 non-null    float64\n",
            " 27   concave_points_worst     569 non-null    float64\n",
            " 28   symmetry_worst           569 non-null    float64\n",
            " 29   fractal_dimension_worst  569 non-null    float64\n",
            "dtypes: float64(30)\n",
            "memory usage: 133.5 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3u7mliUMish",
        "outputId": "b3cb8c3c-a884-43dc-d0ec-eb1b351ef1a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "classe = pd.read_csv(\"https://raw.githubusercontent.com/itimes-digital/deep-learning-estudo/main/dataset/saidas_breast.csv\")\n",
        "classe.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype\n",
            "---  ------  --------------  -----\n",
            " 0   0       569 non-null    int64\n",
            "dtypes: int64(1)\n",
            "memory usage: 4.6 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlNaqOa-MdOC",
        "outputId": "3a87cc8c-a1f5-46f0-b523-93ae4f360888",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "classe.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0\n",
              "0  0\n",
              "1  0\n",
              "2  0\n",
              "3  0\n",
              "4  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g6n8WsidoT3"
      },
      "source": [
        "import keras"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RexXf9H_eAV8"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bFSqKFdjasq"
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtgFqY6pfIcE"
      },
      "source": [
        "Definição do números de neurônios por camada:\n",
        "\n",
        "(numero de entrada + numero de saídas esperada) / 2 = número de units na camada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O4W7keffmao",
        "outputId": "b44766d8-9b0e-4dcc-a3f8-ad86dde88543",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Medida base para definir a quantidade de neurônios na camada.\n",
        "# Como a classificação é binária, a resposta será 0 ou 1, portanto, uma saída.\n",
        "quantSaidaEsperada = 1\n",
        "units = (previsores.columns.size + quantSaidaEsperada) / 2\n",
        "units = np.round(units)\n",
        "units"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQzPFN9Bitpj"
      },
      "source": [
        "def criarRede():\n",
        "  # input_dim define a quantidade de neurônios para a camada de entrada.\n",
        "  classificador = Sequential() # Estrutura básica para colocar as camadas sequencialmente\n",
        "  classificador.add(Dense(units=16, # define a quantidade de neurônios a camada oculta \n",
        "                        activation='relu', \n",
        "                        kernel_initializer='random_uniform', \n",
        "                        input_dim=30));# Quantidade de atributos de entrada\n",
        "\n",
        "  # Camada intermediária ou oculta\n",
        "  classificador.add(Dense(units=16, # define a quantidade de neurônios a camada oculta\n",
        "                        activation='relu', \n",
        "                        kernel_initializer='random_uniform'));\n",
        "\n",
        "  # Definindo a camada de saída\n",
        "  # Como é um classificador binário para 0 ou 1\n",
        "  # A quantidade de neurônio é 1\n",
        "  classificador.add(Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "  otimizador = keras.optimizers.Adam(lr=0.0001, decay = 0.00001, clipvalue = 0.5)\n",
        "  # para classificação binária deve usar binary_crossentropy\n",
        "  # para classificação com mais de duas classes deve usar categorical_crossentropy\n",
        "  classificador.compile(optimizer= otimizador, \n",
        "                      loss='binary_crossentropy',\n",
        "                      metrics=['binary_accuracy']);\n",
        "                  \n",
        "  return classificador; \n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjZEHAGLek7e",
        "outputId": "b93b7985-f76a-4f66-8b91-b2cc656130c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "classificador = KerasClassifier(build_fn = criarRede,\n",
        "                                epochs = 100,\n",
        "                                batch_size = 10);\n",
        "classificador"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier at 0x7f25986290b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYBH2t4uPEY6",
        "outputId": "6d091d92-9f52-4d7e-eeb9-409009c2bc65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "resultados = cross_val_score(estimator = classificador,\n",
        "                             X = previsores, \n",
        "                             y = classe,\n",
        "                             cv = 10,\n",
        "                             scoring = 'accuracy')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.8136 - binary_accuracy: 0.3848\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 962us/step - loss: 0.7064 - binary_accuracy: 0.4941\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5726 - binary_accuracy: 0.6797\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5368 - binary_accuracy: 0.7129\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5104 - binary_accuracy: 0.7012\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 988us/step - loss: 0.4907 - binary_accuracy: 0.7207\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4746 - binary_accuracy: 0.7363\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4613 - binary_accuracy: 0.7715\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4507 - binary_accuracy: 0.7832\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4372 - binary_accuracy: 0.8105\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4254 - binary_accuracy: 0.8281\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4112 - binary_accuracy: 0.8281\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4011 - binary_accuracy: 0.8555\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3924 - binary_accuracy: 0.8535\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3796 - binary_accuracy: 0.8652\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3783 - binary_accuracy: 0.8633\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3722 - binary_accuracy: 0.8574\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3526 - binary_accuracy: 0.8672\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3556 - binary_accuracy: 0.8691\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3518 - binary_accuracy: 0.8730\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 997us/step - loss: 0.3369 - binary_accuracy: 0.8730\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3356 - binary_accuracy: 0.8750\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 960us/step - loss: 0.3223 - binary_accuracy: 0.8789\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 995us/step - loss: 0.3111 - binary_accuracy: 0.8848\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3045 - binary_accuracy: 0.8887\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3027 - binary_accuracy: 0.8867\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3050 - binary_accuracy: 0.8848\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2889 - binary_accuracy: 0.8828\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2884 - binary_accuracy: 0.8906\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2856 - binary_accuracy: 0.8945\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2831 - binary_accuracy: 0.8867\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2705 - binary_accuracy: 0.8926\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2722 - binary_accuracy: 0.9043\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2660 - binary_accuracy: 0.8984\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2572 - binary_accuracy: 0.9043\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2555 - binary_accuracy: 0.9043\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 951us/step - loss: 0.2651 - binary_accuracy: 0.8945\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2737 - binary_accuracy: 0.8867\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2482 - binary_accuracy: 0.9102\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2471 - binary_accuracy: 0.9082\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 958us/step - loss: 0.2456 - binary_accuracy: 0.9062\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2500 - binary_accuracy: 0.9062\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2577 - binary_accuracy: 0.8945\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2471 - binary_accuracy: 0.9023\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2364 - binary_accuracy: 0.9062\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 991us/step - loss: 0.2444 - binary_accuracy: 0.9043\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2333 - binary_accuracy: 0.9102\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2354 - binary_accuracy: 0.9102\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2383 - binary_accuracy: 0.9180\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2339 - binary_accuracy: 0.9062\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 954us/step - loss: 0.2326 - binary_accuracy: 0.9121\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 999us/step - loss: 0.2209 - binary_accuracy: 0.9219\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2207 - binary_accuracy: 0.9160\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2231 - binary_accuracy: 0.9160\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2251 - binary_accuracy: 0.9121\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2304 - binary_accuracy: 0.9219\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 995us/step - loss: 0.2353 - binary_accuracy: 0.9141\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2183 - binary_accuracy: 0.9141\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2247 - binary_accuracy: 0.9180\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2187 - binary_accuracy: 0.9160\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2173 - binary_accuracy: 0.9121\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2176 - binary_accuracy: 0.9219\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2229 - binary_accuracy: 0.9141\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2218 - binary_accuracy: 0.9180\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2130 - binary_accuracy: 0.9160\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2161 - binary_accuracy: 0.9199\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2194 - binary_accuracy: 0.9277\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2137 - binary_accuracy: 0.9258\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2165 - binary_accuracy: 0.9238\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 991us/step - loss: 0.2209 - binary_accuracy: 0.9180\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2093 - binary_accuracy: 0.9277\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2182 - binary_accuracy: 0.9297\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2208 - binary_accuracy: 0.9277\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2159 - binary_accuracy: 0.9180\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2214 - binary_accuracy: 0.9238\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2249 - binary_accuracy: 0.9297\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 987us/step - loss: 0.2107 - binary_accuracy: 0.9277\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 997us/step - loss: 0.2256 - binary_accuracy: 0.9121\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 988us/step - loss: 0.2084 - binary_accuracy: 0.9238\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2015 - binary_accuracy: 0.9219\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2185 - binary_accuracy: 0.9180\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2169 - binary_accuracy: 0.9141\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2122 - binary_accuracy: 0.9238\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2176 - binary_accuracy: 0.9355\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2275 - binary_accuracy: 0.9297\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2086 - binary_accuracy: 0.9297\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2116 - binary_accuracy: 0.9277\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2281 - binary_accuracy: 0.9219\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2088 - binary_accuracy: 0.9258\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2267 - binary_accuracy: 0.9238\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2235 - binary_accuracy: 0.9277\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2169 - binary_accuracy: 0.9277\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2250 - binary_accuracy: 0.9102\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2202 - binary_accuracy: 0.9180\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2280 - binary_accuracy: 0.9219\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2127 - binary_accuracy: 0.9258\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2176 - binary_accuracy: 0.9219\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2207 - binary_accuracy: 0.9297\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2161 - binary_accuracy: 0.9316\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2119 - binary_accuracy: 0.9336\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "Epoch 1/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.8116 - binary_accuracy: 0.6367\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 952us/step - loss: 0.6316 - binary_accuracy: 0.6621\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5638 - binary_accuracy: 0.6758\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5167 - binary_accuracy: 0.7070\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4831 - binary_accuracy: 0.7246\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4636 - binary_accuracy: 0.7539\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4520 - binary_accuracy: 0.7676\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4564 - binary_accuracy: 0.8145\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4367 - binary_accuracy: 0.8242\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4252 - binary_accuracy: 0.8457\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4283 - binary_accuracy: 0.8457\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4151 - binary_accuracy: 0.8574\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4065 - binary_accuracy: 0.8535\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3974 - binary_accuracy: 0.8691\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4060 - binary_accuracy: 0.8574\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3951 - binary_accuracy: 0.8730\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3824 - binary_accuracy: 0.8730\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3792 - binary_accuracy: 0.8652\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3767 - binary_accuracy: 0.8672\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3732 - binary_accuracy: 0.8711\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3647 - binary_accuracy: 0.8730\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3569 - binary_accuracy: 0.8750\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3614 - binary_accuracy: 0.8672\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3417 - binary_accuracy: 0.8770\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3472 - binary_accuracy: 0.8691\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3547 - binary_accuracy: 0.8652\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3385 - binary_accuracy: 0.8730\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3304 - binary_accuracy: 0.8789\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3400 - binary_accuracy: 0.8770\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3329 - binary_accuracy: 0.8770\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3446 - binary_accuracy: 0.8809\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3308 - binary_accuracy: 0.8789\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3231 - binary_accuracy: 0.8789\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3347 - binary_accuracy: 0.8789\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3506 - binary_accuracy: 0.8848\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3283 - binary_accuracy: 0.8945\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3214 - binary_accuracy: 0.8848\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3069 - binary_accuracy: 0.8828\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3061 - binary_accuracy: 0.8906\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3020 - binary_accuracy: 0.8828\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3128 - binary_accuracy: 0.8887\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3038 - binary_accuracy: 0.8887\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3022 - binary_accuracy: 0.8789\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2986 - binary_accuracy: 0.8809\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3051 - binary_accuracy: 0.8945\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3011 - binary_accuracy: 0.8867\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2997 - binary_accuracy: 0.8926\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2887 - binary_accuracy: 0.8867\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2902 - binary_accuracy: 0.8945\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2849 - binary_accuracy: 0.8887\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2830 - binary_accuracy: 0.8926\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2870 - binary_accuracy: 0.8848\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3076 - binary_accuracy: 0.8867\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2948 - binary_accuracy: 0.8906\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2841 - binary_accuracy: 0.8926\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2949 - binary_accuracy: 0.8848\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3017 - binary_accuracy: 0.8789\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2823 - binary_accuracy: 0.8867\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2950 - binary_accuracy: 0.8965\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2885 - binary_accuracy: 0.8867\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2795 - binary_accuracy: 0.8945\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2717 - binary_accuracy: 0.9062\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2680 - binary_accuracy: 0.9043\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2722 - binary_accuracy: 0.9023\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2635 - binary_accuracy: 0.9102\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2523 - binary_accuracy: 0.9062\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2674 - binary_accuracy: 0.9004\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2662 - binary_accuracy: 0.8965\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2527 - binary_accuracy: 0.9043\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2545 - binary_accuracy: 0.9062\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2535 - binary_accuracy: 0.9023\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2581 - binary_accuracy: 0.9043\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2552 - binary_accuracy: 0.9004\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 991us/step - loss: 0.2548 - binary_accuracy: 0.9102\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 986us/step - loss: 0.2529 - binary_accuracy: 0.9023\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2671 - binary_accuracy: 0.9043\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2566 - binary_accuracy: 0.9062\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2515 - binary_accuracy: 0.8945\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2349 - binary_accuracy: 0.9023\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2523 - binary_accuracy: 0.9062\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2586 - binary_accuracy: 0.9043\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2408 - binary_accuracy: 0.9121\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2448 - binary_accuracy: 0.9023\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2373 - binary_accuracy: 0.9121\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2424 - binary_accuracy: 0.9043\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2399 - binary_accuracy: 0.9062\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2421 - binary_accuracy: 0.9082\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2565 - binary_accuracy: 0.9062\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2475 - binary_accuracy: 0.9023\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2439 - binary_accuracy: 0.9062\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2524 - binary_accuracy: 0.9102\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2496 - binary_accuracy: 0.9043\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2556 - binary_accuracy: 0.8945\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2439 - binary_accuracy: 0.9102\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2411 - binary_accuracy: 0.9023\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2593 - binary_accuracy: 0.9121\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2480 - binary_accuracy: 0.9023\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2538 - binary_accuracy: 0.9062\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2582 - binary_accuracy: 0.9121\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2479 - binary_accuracy: 0.9102\n",
            "Epoch 1/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.5561 - binary_accuracy: 0.5254\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5973 - binary_accuracy: 0.6582\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5223 - binary_accuracy: 0.6895\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4868 - binary_accuracy: 0.7344\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4594 - binary_accuracy: 0.7812\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4565 - binary_accuracy: 0.7539\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4167 - binary_accuracy: 0.8340\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4225 - binary_accuracy: 0.8008\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3996 - binary_accuracy: 0.8438\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3862 - binary_accuracy: 0.8535\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3827 - binary_accuracy: 0.8301\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3761 - binary_accuracy: 0.8477\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3768 - binary_accuracy: 0.8496\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3756 - binary_accuracy: 0.8516\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3622 - binary_accuracy: 0.8457\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3632 - binary_accuracy: 0.8555\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3529 - binary_accuracy: 0.8652\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3587 - binary_accuracy: 0.8652\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3453 - binary_accuracy: 0.8633\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3535 - binary_accuracy: 0.8535\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3647 - binary_accuracy: 0.8535\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3529 - binary_accuracy: 0.8652\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3511 - binary_accuracy: 0.8672\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3395 - binary_accuracy: 0.8730\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3323 - binary_accuracy: 0.8691\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3345 - binary_accuracy: 0.8672\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3382 - binary_accuracy: 0.8633\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3272 - binary_accuracy: 0.8730\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3304 - binary_accuracy: 0.8652\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3365 - binary_accuracy: 0.8867\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3286 - binary_accuracy: 0.8828\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3208 - binary_accuracy: 0.8789\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3288 - binary_accuracy: 0.8711\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3424 - binary_accuracy: 0.8652\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3308 - binary_accuracy: 0.8672\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3219 - binary_accuracy: 0.8770\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3263 - binary_accuracy: 0.8926\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3333 - binary_accuracy: 0.8750\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3245 - binary_accuracy: 0.8730\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3358 - binary_accuracy: 0.8848\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3363 - binary_accuracy: 0.8750\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3685 - binary_accuracy: 0.8770\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3304 - binary_accuracy: 0.8750\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3247 - binary_accuracy: 0.8828\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3315 - binary_accuracy: 0.8867\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3283 - binary_accuracy: 0.8809\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3378 - binary_accuracy: 0.8848\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3179 - binary_accuracy: 0.8906\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3340 - binary_accuracy: 0.8926\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3283 - binary_accuracy: 0.8770\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3166 - binary_accuracy: 0.8848\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3454 - binary_accuracy: 0.8809\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3306 - binary_accuracy: 0.8770\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3335 - binary_accuracy: 0.8633\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3388 - binary_accuracy: 0.8867\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3214 - binary_accuracy: 0.8848\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3420 - binary_accuracy: 0.8691\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3175 - binary_accuracy: 0.8887\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3271 - binary_accuracy: 0.8770\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3203 - binary_accuracy: 0.8770\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3373 - binary_accuracy: 0.8750\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3361 - binary_accuracy: 0.8828\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3216 - binary_accuracy: 0.8848\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3300 - binary_accuracy: 0.8789\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3224 - binary_accuracy: 0.8867\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3268 - binary_accuracy: 0.8887\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3342 - binary_accuracy: 0.8887\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3311 - binary_accuracy: 0.8750\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3268 - binary_accuracy: 0.8984\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3176 - binary_accuracy: 0.8750\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3380 - binary_accuracy: 0.8828\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3332 - binary_accuracy: 0.8867\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3239 - binary_accuracy: 0.8809\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3300 - binary_accuracy: 0.8906\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3519 - binary_accuracy: 0.8711\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3849 - binary_accuracy: 0.8750\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3412 - binary_accuracy: 0.8809\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3748 - binary_accuracy: 0.8613\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3571 - binary_accuracy: 0.8809\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3418 - binary_accuracy: 0.8867\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3298 - binary_accuracy: 0.8848\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3323 - binary_accuracy: 0.8867\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3351 - binary_accuracy: 0.8887\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3255 - binary_accuracy: 0.8887\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3511 - binary_accuracy: 0.8789\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3365 - binary_accuracy: 0.8848\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3323 - binary_accuracy: 0.8906\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3586 - binary_accuracy: 0.8828\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3453 - binary_accuracy: 0.8789\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3498 - binary_accuracy: 0.8770\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3526 - binary_accuracy: 0.8828\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3594 - binary_accuracy: 0.8867\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3536 - binary_accuracy: 0.8965\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3544 - binary_accuracy: 0.8691\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3836 - binary_accuracy: 0.8730\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3903 - binary_accuracy: 0.8633\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3587 - binary_accuracy: 0.8750\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3754 - binary_accuracy: 0.8711\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3628 - binary_accuracy: 0.8809\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3687 - binary_accuracy: 0.8770\n",
            "Epoch 1/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.0595 - binary_accuracy: 0.5195\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.7603 - binary_accuracy: 0.5234\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.6462 - binary_accuracy: 0.5645\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5954 - binary_accuracy: 0.6543\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5662 - binary_accuracy: 0.6660\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5485 - binary_accuracy: 0.6426\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5405 - binary_accuracy: 0.6914\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5198 - binary_accuracy: 0.6719\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4828 - binary_accuracy: 0.7246\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4459 - binary_accuracy: 0.7852\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4276 - binary_accuracy: 0.8223\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4119 - binary_accuracy: 0.8262\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4054 - binary_accuracy: 0.8359\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3941 - binary_accuracy: 0.8496\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3915 - binary_accuracy: 0.8379\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3814 - binary_accuracy: 0.8652\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3735 - binary_accuracy: 0.8652\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3728 - binary_accuracy: 0.8652\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3722 - binary_accuracy: 0.8613\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3591 - binary_accuracy: 0.8770\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3541 - binary_accuracy: 0.8633\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3464 - binary_accuracy: 0.8711\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3483 - binary_accuracy: 0.8672\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3398 - binary_accuracy: 0.8652\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3398 - binary_accuracy: 0.8691\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3373 - binary_accuracy: 0.8691\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3351 - binary_accuracy: 0.8730\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3281 - binary_accuracy: 0.8730\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3311 - binary_accuracy: 0.8867\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3195 - binary_accuracy: 0.8828\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3178 - binary_accuracy: 0.8730\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3178 - binary_accuracy: 0.8809\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3136 - binary_accuracy: 0.8750\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3098 - binary_accuracy: 0.8906\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3027 - binary_accuracy: 0.8965\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3113 - binary_accuracy: 0.8906\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3000 - binary_accuracy: 0.8867\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2987 - binary_accuracy: 0.8867\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3002 - binary_accuracy: 0.8828\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3107 - binary_accuracy: 0.8848\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2944 - binary_accuracy: 0.9004\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2995 - binary_accuracy: 0.8848\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2951 - binary_accuracy: 0.8848\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2912 - binary_accuracy: 0.8984\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2961 - binary_accuracy: 0.8965\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2943 - binary_accuracy: 0.8965\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2989 - binary_accuracy: 0.9004\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2915 - binary_accuracy: 0.8945\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2908 - binary_accuracy: 0.8906\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2817 - binary_accuracy: 0.9023\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2892 - binary_accuracy: 0.9004\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2768 - binary_accuracy: 0.9043\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2766 - binary_accuracy: 0.8984\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2753 - binary_accuracy: 0.9004\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2802 - binary_accuracy: 0.9004\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2709 - binary_accuracy: 0.8984\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2678 - binary_accuracy: 0.9043\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2765 - binary_accuracy: 0.9023\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2627 - binary_accuracy: 0.9062\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2666 - binary_accuracy: 0.8984\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2744 - binary_accuracy: 0.9004\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2582 - binary_accuracy: 0.9141\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2516 - binary_accuracy: 0.9141\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2522 - binary_accuracy: 0.9258\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2667 - binary_accuracy: 0.9082\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2507 - binary_accuracy: 0.9219\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2484 - binary_accuracy: 0.9219\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2486 - binary_accuracy: 0.9160\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2417 - binary_accuracy: 0.9199\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2476 - binary_accuracy: 0.9160\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2408 - binary_accuracy: 0.9199\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2495 - binary_accuracy: 0.9082\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2400 - binary_accuracy: 0.9199\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2505 - binary_accuracy: 0.9160\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2426 - binary_accuracy: 0.9160\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2445 - binary_accuracy: 0.9160\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2435 - binary_accuracy: 0.9180\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2684 - binary_accuracy: 0.8945\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2522 - binary_accuracy: 0.9102\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2431 - binary_accuracy: 0.9102\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2464 - binary_accuracy: 0.8945\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2626 - binary_accuracy: 0.9082\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2404 - binary_accuracy: 0.9180\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2400 - binary_accuracy: 0.9141\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2562 - binary_accuracy: 0.9082\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2459 - binary_accuracy: 0.9121\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2840 - binary_accuracy: 0.8945\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2408 - binary_accuracy: 0.9141\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2402 - binary_accuracy: 0.9121\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2599 - binary_accuracy: 0.9043\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2400 - binary_accuracy: 0.9199\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2526 - binary_accuracy: 0.9141\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2529 - binary_accuracy: 0.9043\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2435 - binary_accuracy: 0.9141\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2372 - binary_accuracy: 0.9180\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2409 - binary_accuracy: 0.9121\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2316 - binary_accuracy: 0.9180\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2535 - binary_accuracy: 0.9121\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2289 - binary_accuracy: 0.9199\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2277 - binary_accuracy: 0.9297\n",
            "Epoch 1/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.0160 - binary_accuracy: 0.6230\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.8192 - binary_accuracy: 0.6484\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.7167 - binary_accuracy: 0.6758\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.6633 - binary_accuracy: 0.6875\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.6240 - binary_accuracy: 0.6973\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5845 - binary_accuracy: 0.7090\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5614 - binary_accuracy: 0.7266\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5448 - binary_accuracy: 0.7363\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5211 - binary_accuracy: 0.7461\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5162 - binary_accuracy: 0.7344\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4904 - binary_accuracy: 0.7402\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4810 - binary_accuracy: 0.7578\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4611 - binary_accuracy: 0.7637\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4430 - binary_accuracy: 0.7988\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4362 - binary_accuracy: 0.7852\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4291 - binary_accuracy: 0.8379\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4207 - binary_accuracy: 0.8457\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4042 - binary_accuracy: 0.8398\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4024 - binary_accuracy: 0.8418\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3870 - binary_accuracy: 0.8594\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3836 - binary_accuracy: 0.8496\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3848 - binary_accuracy: 0.8750\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3736 - binary_accuracy: 0.8555\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3681 - binary_accuracy: 0.8691\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3736 - binary_accuracy: 0.8574\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3567 - binary_accuracy: 0.8789\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3603 - binary_accuracy: 0.8691\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3591 - binary_accuracy: 0.8652\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3511 - binary_accuracy: 0.8730\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3459 - binary_accuracy: 0.8828\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3406 - binary_accuracy: 0.8770\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3298 - binary_accuracy: 0.8770\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3414 - binary_accuracy: 0.8750\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3301 - binary_accuracy: 0.8965\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3293 - binary_accuracy: 0.8867\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3282 - binary_accuracy: 0.8887\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3415 - binary_accuracy: 0.8691\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3224 - binary_accuracy: 0.8770\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3173 - binary_accuracy: 0.8848\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3098 - binary_accuracy: 0.8906\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3105 - binary_accuracy: 0.8926\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3076 - binary_accuracy: 0.8945\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3053 - binary_accuracy: 0.8926\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2984 - binary_accuracy: 0.8984\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2984 - binary_accuracy: 0.8984\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2908 - binary_accuracy: 0.8965\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2975 - binary_accuracy: 0.8945\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2892 - binary_accuracy: 0.9082\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2871 - binary_accuracy: 0.9004\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2855 - binary_accuracy: 0.8965\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3034 - binary_accuracy: 0.8965\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2790 - binary_accuracy: 0.9023\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2783 - binary_accuracy: 0.8965\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2793 - binary_accuracy: 0.8945\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2740 - binary_accuracy: 0.9043\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2789 - binary_accuracy: 0.9004\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2798 - binary_accuracy: 0.9082\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2794 - binary_accuracy: 0.9102\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2698 - binary_accuracy: 0.8945\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2766 - binary_accuracy: 0.9102\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2616 - binary_accuracy: 0.9043\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2608 - binary_accuracy: 0.9062\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2592 - binary_accuracy: 0.9043\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2605 - binary_accuracy: 0.9023\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2552 - binary_accuracy: 0.9180\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2696 - binary_accuracy: 0.8984\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2526 - binary_accuracy: 0.9121\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2528 - binary_accuracy: 0.9121\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2518 - binary_accuracy: 0.9062\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2505 - binary_accuracy: 0.9102\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2558 - binary_accuracy: 0.9121\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2534 - binary_accuracy: 0.8984\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2546 - binary_accuracy: 0.9082\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2497 - binary_accuracy: 0.9023\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2582 - binary_accuracy: 0.9102\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2628 - binary_accuracy: 0.9121\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2490 - binary_accuracy: 0.9160\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2458 - binary_accuracy: 0.9160\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2410 - binary_accuracy: 0.9062\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2450 - binary_accuracy: 0.9062\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2612 - binary_accuracy: 0.9004\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2661 - binary_accuracy: 0.9004\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2565 - binary_accuracy: 0.9082\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2483 - binary_accuracy: 0.9023\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2398 - binary_accuracy: 0.9160\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2672 - binary_accuracy: 0.8965\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2639 - binary_accuracy: 0.9121\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2347 - binary_accuracy: 0.9180\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2530 - binary_accuracy: 0.9062\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2529 - binary_accuracy: 0.9062\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2391 - binary_accuracy: 0.9141\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2574 - binary_accuracy: 0.9141\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2488 - binary_accuracy: 0.9082\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2378 - binary_accuracy: 0.9180\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2551 - binary_accuracy: 0.9082\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2335 - binary_accuracy: 0.9219\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2596 - binary_accuracy: 0.9004\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2329 - binary_accuracy: 0.9160\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2476 - binary_accuracy: 0.9121\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2266 - binary_accuracy: 0.9180\n",
            "Epoch 1/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.2807 - binary_accuracy: 0.5801\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.6830 - binary_accuracy: 0.6074\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.6187 - binary_accuracy: 0.6445\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5708 - binary_accuracy: 0.6777\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5456 - binary_accuracy: 0.6660\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5079 - binary_accuracy: 0.7227\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4804 - binary_accuracy: 0.7188\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4756 - binary_accuracy: 0.7246\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4593 - binary_accuracy: 0.7363\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4843 - binary_accuracy: 0.7383\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4546 - binary_accuracy: 0.7539\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4467 - binary_accuracy: 0.7539\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4332 - binary_accuracy: 0.7676\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4346 - binary_accuracy: 0.7969\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4431 - binary_accuracy: 0.7910\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4300 - binary_accuracy: 0.7988\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4229 - binary_accuracy: 0.7891\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4230 - binary_accuracy: 0.8047\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4118 - binary_accuracy: 0.8359\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4102 - binary_accuracy: 0.8086\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4158 - binary_accuracy: 0.8223\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4071 - binary_accuracy: 0.8320\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4058 - binary_accuracy: 0.8359\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3978 - binary_accuracy: 0.8398\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3814 - binary_accuracy: 0.8496\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3784 - binary_accuracy: 0.8145\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3711 - binary_accuracy: 0.8555\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3671 - binary_accuracy: 0.8613\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3617 - binary_accuracy: 0.8633\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3661 - binary_accuracy: 0.8457\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3560 - binary_accuracy: 0.8613\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3495 - binary_accuracy: 0.8555\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3537 - binary_accuracy: 0.8535\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3445 - binary_accuracy: 0.8574\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3482 - binary_accuracy: 0.8555\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3385 - binary_accuracy: 0.8730\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3284 - binary_accuracy: 0.8730\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3357 - binary_accuracy: 0.8730\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3291 - binary_accuracy: 0.8750\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3275 - binary_accuracy: 0.8730\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3231 - binary_accuracy: 0.8848\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3206 - binary_accuracy: 0.8770\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3208 - binary_accuracy: 0.8730\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3241 - binary_accuracy: 0.8770\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3223 - binary_accuracy: 0.8770\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3256 - binary_accuracy: 0.8730\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3257 - binary_accuracy: 0.8750\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3240 - binary_accuracy: 0.8770\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3204 - binary_accuracy: 0.8770\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3155 - binary_accuracy: 0.8809\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3169 - binary_accuracy: 0.8633\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3152 - binary_accuracy: 0.8828\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3173 - binary_accuracy: 0.8828\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3068 - binary_accuracy: 0.8945\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3012 - binary_accuracy: 0.8828\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2991 - binary_accuracy: 0.8926\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3036 - binary_accuracy: 0.8926\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2986 - binary_accuracy: 0.8926\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3342 - binary_accuracy: 0.8691\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3120 - binary_accuracy: 0.8652\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2957 - binary_accuracy: 0.8711\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3079 - binary_accuracy: 0.8828\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3020 - binary_accuracy: 0.8711\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2914 - binary_accuracy: 0.8926\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2747 - binary_accuracy: 0.9141\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2892 - binary_accuracy: 0.8750\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2961 - binary_accuracy: 0.8945\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2798 - binary_accuracy: 0.9082\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2747 - binary_accuracy: 0.8965\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2997 - binary_accuracy: 0.8906\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2837 - binary_accuracy: 0.8945\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2788 - binary_accuracy: 0.8906\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2736 - binary_accuracy: 0.8867\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2748 - binary_accuracy: 0.8984\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2753 - binary_accuracy: 0.8906\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2768 - binary_accuracy: 0.8867\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2761 - binary_accuracy: 0.8984\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2761 - binary_accuracy: 0.8965\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2738 - binary_accuracy: 0.8867\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2697 - binary_accuracy: 0.9062\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2894 - binary_accuracy: 0.8848\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2692 - binary_accuracy: 0.8926\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2853 - binary_accuracy: 0.8906\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2696 - binary_accuracy: 0.8926\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2624 - binary_accuracy: 0.8984\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2692 - binary_accuracy: 0.9023\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2617 - binary_accuracy: 0.9043\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2655 - binary_accuracy: 0.8965\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2560 - binary_accuracy: 0.9082\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2507 - binary_accuracy: 0.9199\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2892 - binary_accuracy: 0.9121\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2658 - binary_accuracy: 0.9004\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2597 - binary_accuracy: 0.8965\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2767 - binary_accuracy: 0.8984\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2639 - binary_accuracy: 0.9082\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2532 - binary_accuracy: 0.9082\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2562 - binary_accuracy: 0.9023\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2717 - binary_accuracy: 0.9102\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2573 - binary_accuracy: 0.8926\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2628 - binary_accuracy: 0.9102\n",
            "Epoch 1/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.8585 - binary_accuracy: 0.6094\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5802 - binary_accuracy: 0.6484\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5248 - binary_accuracy: 0.6562\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5149 - binary_accuracy: 0.6641\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4917 - binary_accuracy: 0.6797\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4695 - binary_accuracy: 0.6816\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4513 - binary_accuracy: 0.7188\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4422 - binary_accuracy: 0.7500\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4296 - binary_accuracy: 0.7441\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4269 - binary_accuracy: 0.8164\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4143 - binary_accuracy: 0.7891\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4169 - binary_accuracy: 0.8262\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4072 - binary_accuracy: 0.8359\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4069 - binary_accuracy: 0.8086\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3962 - binary_accuracy: 0.8379\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3913 - binary_accuracy: 0.8457\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3863 - binary_accuracy: 0.8496\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3865 - binary_accuracy: 0.8574\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3796 - binary_accuracy: 0.8633\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3918 - binary_accuracy: 0.8438\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3677 - binary_accuracy: 0.8633\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3632 - binary_accuracy: 0.8594\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3565 - binary_accuracy: 0.8711\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3505 - binary_accuracy: 0.8867\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3513 - binary_accuracy: 0.8750\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3531 - binary_accuracy: 0.8730\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3431 - binary_accuracy: 0.8750\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3341 - binary_accuracy: 0.8730\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3413 - binary_accuracy: 0.8691\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3266 - binary_accuracy: 0.8809\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3245 - binary_accuracy: 0.8828\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3197 - binary_accuracy: 0.8945\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3154 - binary_accuracy: 0.8867\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3133 - binary_accuracy: 0.8965\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3020 - binary_accuracy: 0.8984\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3183 - binary_accuracy: 0.8672\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2980 - binary_accuracy: 0.8906\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2980 - binary_accuracy: 0.8848\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3244 - binary_accuracy: 0.8887\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2919 - binary_accuracy: 0.8926\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3147 - binary_accuracy: 0.8945\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2978 - binary_accuracy: 0.8984\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3017 - binary_accuracy: 0.8789\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2921 - binary_accuracy: 0.8984\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2928 - binary_accuracy: 0.9004\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2919 - binary_accuracy: 0.8906\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2828 - binary_accuracy: 0.9023\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2833 - binary_accuracy: 0.9062\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2801 - binary_accuracy: 0.8965\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2795 - binary_accuracy: 0.9082\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2806 - binary_accuracy: 0.9062\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2777 - binary_accuracy: 0.8984\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2829 - binary_accuracy: 0.8945\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2766 - binary_accuracy: 0.9023\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2844 - binary_accuracy: 0.8984\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2687 - binary_accuracy: 0.8945\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2802 - binary_accuracy: 0.8965\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2743 - binary_accuracy: 0.8984\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2720 - binary_accuracy: 0.9043\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2758 - binary_accuracy: 0.9121\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2621 - binary_accuracy: 0.9082\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2574 - binary_accuracy: 0.9043\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2818 - binary_accuracy: 0.9121\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2595 - binary_accuracy: 0.9102\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2762 - binary_accuracy: 0.8965\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2935 - binary_accuracy: 0.8848\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2567 - binary_accuracy: 0.9102\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2651 - binary_accuracy: 0.9043\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2715 - binary_accuracy: 0.9043\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2766 - binary_accuracy: 0.8984\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2774 - binary_accuracy: 0.9082\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2769 - binary_accuracy: 0.9004\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2676 - binary_accuracy: 0.8984\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2643 - binary_accuracy: 0.9102\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2738 - binary_accuracy: 0.9043\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2671 - binary_accuracy: 0.9023\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2627 - binary_accuracy: 0.9082\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2695 - binary_accuracy: 0.9062\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2592 - binary_accuracy: 0.9141\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2573 - binary_accuracy: 0.9121\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2657 - binary_accuracy: 0.9121\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2523 - binary_accuracy: 0.9023\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2666 - binary_accuracy: 0.9062\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2656 - binary_accuracy: 0.8984\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2573 - binary_accuracy: 0.9141\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2677 - binary_accuracy: 0.8984\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2704 - binary_accuracy: 0.9082\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2610 - binary_accuracy: 0.9082\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2618 - binary_accuracy: 0.9199\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2619 - binary_accuracy: 0.9062\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2630 - binary_accuracy: 0.9062\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3146 - binary_accuracy: 0.8945\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2679 - binary_accuracy: 0.9082\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2781 - binary_accuracy: 0.9121\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2786 - binary_accuracy: 0.9004\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2749 - binary_accuracy: 0.9121\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2852 - binary_accuracy: 0.9043\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2697 - binary_accuracy: 0.9082\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2829 - binary_accuracy: 0.9062\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2862 - binary_accuracy: 0.9102\n",
            "Epoch 1/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.2157 - binary_accuracy: 0.6230\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6351 - binary_accuracy: 0.6289\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5702 - binary_accuracy: 0.6602\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5507 - binary_accuracy: 0.6582\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5267 - binary_accuracy: 0.6660\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5135 - binary_accuracy: 0.6875\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5079 - binary_accuracy: 0.7188\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4935 - binary_accuracy: 0.7148\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4811 - binary_accuracy: 0.7344\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4781 - binary_accuracy: 0.7871\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4671 - binary_accuracy: 0.7949\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4628 - binary_accuracy: 0.7344\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4647 - binary_accuracy: 0.7812\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4523 - binary_accuracy: 0.7656\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4504 - binary_accuracy: 0.8184\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4548 - binary_accuracy: 0.8320\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4457 - binary_accuracy: 0.8105\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4404 - binary_accuracy: 0.8164\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4355 - binary_accuracy: 0.8145\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4269 - binary_accuracy: 0.8398\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4103 - binary_accuracy: 0.8223\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4226 - binary_accuracy: 0.8438\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4087 - binary_accuracy: 0.8613\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4073 - binary_accuracy: 0.8652\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3996 - binary_accuracy: 0.8672\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4003 - binary_accuracy: 0.8594\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3954 - binary_accuracy: 0.8516\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3886 - binary_accuracy: 0.8535\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3699 - binary_accuracy: 0.8594\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3656 - binary_accuracy: 0.8789\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3589 - binary_accuracy: 0.8750\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3618 - binary_accuracy: 0.8652\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3566 - binary_accuracy: 0.8652\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3454 - binary_accuracy: 0.8711\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3460 - binary_accuracy: 0.8809\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3482 - binary_accuracy: 0.8711\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3322 - binary_accuracy: 0.8789\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3381 - binary_accuracy: 0.8770\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3278 - binary_accuracy: 0.8789\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3257 - binary_accuracy: 0.8555\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3220 - binary_accuracy: 0.8770\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3209 - binary_accuracy: 0.8691\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3159 - binary_accuracy: 0.8789\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3018 - binary_accuracy: 0.8809\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3100 - binary_accuracy: 0.8730\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3112 - binary_accuracy: 0.8750\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3060 - binary_accuracy: 0.8730\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3163 - binary_accuracy: 0.8711\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3029 - binary_accuracy: 0.8809\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2939 - binary_accuracy: 0.8828\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2976 - binary_accuracy: 0.8926\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3004 - binary_accuracy: 0.8809\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2931 - binary_accuracy: 0.8809\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2859 - binary_accuracy: 0.8945\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2860 - binary_accuracy: 0.8789\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2825 - binary_accuracy: 0.8809\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2847 - binary_accuracy: 0.8867\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2813 - binary_accuracy: 0.9004\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2825 - binary_accuracy: 0.8730\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2773 - binary_accuracy: 0.9023\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2841 - binary_accuracy: 0.8887\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2695 - binary_accuracy: 0.8945\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2824 - binary_accuracy: 0.9004\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2708 - binary_accuracy: 0.9004\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2724 - binary_accuracy: 0.8984\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2680 - binary_accuracy: 0.8906\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2671 - binary_accuracy: 0.8984\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2651 - binary_accuracy: 0.8984\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2601 - binary_accuracy: 0.9062\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2621 - binary_accuracy: 0.8965\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2656 - binary_accuracy: 0.9121\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2593 - binary_accuracy: 0.9102\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2662 - binary_accuracy: 0.9043\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2641 - binary_accuracy: 0.8965\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2678 - binary_accuracy: 0.9043\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2579 - binary_accuracy: 0.9062\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2574 - binary_accuracy: 0.9082\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2552 - binary_accuracy: 0.9121\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2555 - binary_accuracy: 0.9043\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2592 - binary_accuracy: 0.9062\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2613 - binary_accuracy: 0.9062\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2549 - binary_accuracy: 0.9082\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2438 - binary_accuracy: 0.9062\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2651 - binary_accuracy: 0.8984\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2611 - binary_accuracy: 0.9141\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2522 - binary_accuracy: 0.9062\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2477 - binary_accuracy: 0.8965\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2584 - binary_accuracy: 0.9062\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2617 - binary_accuracy: 0.9121\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2506 - binary_accuracy: 0.9121\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2493 - binary_accuracy: 0.9102\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2515 - binary_accuracy: 0.9102\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2485 - binary_accuracy: 0.9082\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2721 - binary_accuracy: 0.9004\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2581 - binary_accuracy: 0.9062\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2490 - binary_accuracy: 0.9004\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2471 - binary_accuracy: 0.9082\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2419 - binary_accuracy: 0.9004\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2442 - binary_accuracy: 0.9160\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2537 - binary_accuracy: 0.9102\n",
            "Epoch 1/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.1098 - binary_accuracy: 0.6035\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5687 - binary_accuracy: 0.6895\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5040 - binary_accuracy: 0.7188\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4803 - binary_accuracy: 0.7324\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4644 - binary_accuracy: 0.7324\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4549 - binary_accuracy: 0.7461\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4429 - binary_accuracy: 0.7734\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4344 - binary_accuracy: 0.7656\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4243 - binary_accuracy: 0.7969\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4161 - binary_accuracy: 0.8105\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3983 - binary_accuracy: 0.8125\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3998 - binary_accuracy: 0.8379\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3840 - binary_accuracy: 0.8555\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3817 - binary_accuracy: 0.8262\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3767 - binary_accuracy: 0.8652\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3680 - binary_accuracy: 0.8672\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3555 - binary_accuracy: 0.8750\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3585 - binary_accuracy: 0.8770\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3491 - binary_accuracy: 0.8887\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3512 - binary_accuracy: 0.8652\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3459 - binary_accuracy: 0.8789\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3497 - binary_accuracy: 0.8691\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3429 - binary_accuracy: 0.8691\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3456 - binary_accuracy: 0.8926\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3420 - binary_accuracy: 0.8770\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3486 - binary_accuracy: 0.8750\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3332 - binary_accuracy: 0.8828\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3300 - binary_accuracy: 0.8691\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3323 - binary_accuracy: 0.8906\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3296 - binary_accuracy: 0.8809\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3245 - binary_accuracy: 0.8887\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3219 - binary_accuracy: 0.8828\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3235 - binary_accuracy: 0.8848\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3258 - binary_accuracy: 0.8965\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3190 - binary_accuracy: 0.8945\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3126 - binary_accuracy: 0.8965\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3265 - binary_accuracy: 0.8867\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3022 - binary_accuracy: 0.8789\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3138 - binary_accuracy: 0.8926\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3130 - binary_accuracy: 0.8887\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3081 - binary_accuracy: 0.8945\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3132 - binary_accuracy: 0.8926\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3117 - binary_accuracy: 0.8848\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3111 - binary_accuracy: 0.8828\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3235 - binary_accuracy: 0.8906\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3275 - binary_accuracy: 0.8887\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3047 - binary_accuracy: 0.8789\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3195 - binary_accuracy: 0.8906\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3067 - binary_accuracy: 0.8848\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3042 - binary_accuracy: 0.8867\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3102 - binary_accuracy: 0.9004\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3098 - binary_accuracy: 0.9004\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3106 - binary_accuracy: 0.8848\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3103 - binary_accuracy: 0.8984\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3009 - binary_accuracy: 0.8887\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3131 - binary_accuracy: 0.8828\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3190 - binary_accuracy: 0.8828\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2981 - binary_accuracy: 0.8848\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3015 - binary_accuracy: 0.8984\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3182 - binary_accuracy: 0.8848\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2932 - binary_accuracy: 0.8809\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3091 - binary_accuracy: 0.8906\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3164 - binary_accuracy: 0.8984\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2925 - binary_accuracy: 0.8887\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3044 - binary_accuracy: 0.8867\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2880 - binary_accuracy: 0.9004\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3285 - binary_accuracy: 0.8848\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2922 - binary_accuracy: 0.9004\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2933 - binary_accuracy: 0.8984\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3061 - binary_accuracy: 0.8887\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2967 - binary_accuracy: 0.9062\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2836 - binary_accuracy: 0.9023\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3069 - binary_accuracy: 0.8984\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2916 - binary_accuracy: 0.8906\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3078 - binary_accuracy: 0.8945\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3173 - binary_accuracy: 0.9121\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2972 - binary_accuracy: 0.8945\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3176 - binary_accuracy: 0.8906\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2971 - binary_accuracy: 0.9043\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2995 - binary_accuracy: 0.8945\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3065 - binary_accuracy: 0.8887\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3122 - binary_accuracy: 0.8945\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3063 - binary_accuracy: 0.8906\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3016 - binary_accuracy: 0.8965\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2889 - binary_accuracy: 0.9062\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2997 - binary_accuracy: 0.9043\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3008 - binary_accuracy: 0.9082\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3207 - binary_accuracy: 0.9023\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3108 - binary_accuracy: 0.9043\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3114 - binary_accuracy: 0.8906\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3227 - binary_accuracy: 0.9121\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3224 - binary_accuracy: 0.9082\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3275 - binary_accuracy: 0.9062\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2995 - binary_accuracy: 0.8945\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3437 - binary_accuracy: 0.8965\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3380 - binary_accuracy: 0.8965\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3252 - binary_accuracy: 0.9062\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3209 - binary_accuracy: 0.8945\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3248 - binary_accuracy: 0.9004\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3093 - binary_accuracy: 0.8965\n",
            "Epoch 1/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 7.4550 - binary_accuracy: 0.5224\n",
            "Epoch 2/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 2.7650 - binary_accuracy: 0.4152\n",
            "Epoch 3/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 1.1910 - binary_accuracy: 0.5517\n",
            "Epoch 4/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6270 - binary_accuracy: 0.6355\n",
            "Epoch 5/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5975 - binary_accuracy: 0.6823\n",
            "Epoch 6/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.5218 - binary_accuracy: 0.7076\n",
            "Epoch 7/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5036 - binary_accuracy: 0.7232\n",
            "Epoch 8/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4810 - binary_accuracy: 0.7290\n",
            "Epoch 9/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4737 - binary_accuracy: 0.7505\n",
            "Epoch 10/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4838 - binary_accuracy: 0.7622\n",
            "Epoch 11/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4436 - binary_accuracy: 0.7700\n",
            "Epoch 12/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4315 - binary_accuracy: 0.8129\n",
            "Epoch 13/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4196 - binary_accuracy: 0.8070\n",
            "Epoch 14/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4074 - binary_accuracy: 0.8246\n",
            "Epoch 15/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.4087 - binary_accuracy: 0.8109\n",
            "Epoch 16/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4034 - binary_accuracy: 0.8226\n",
            "Epoch 17/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3995 - binary_accuracy: 0.8207\n",
            "Epoch 18/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3792 - binary_accuracy: 0.8363\n",
            "Epoch 19/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3847 - binary_accuracy: 0.8441\n",
            "Epoch 20/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3646 - binary_accuracy: 0.8558\n",
            "Epoch 21/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3672 - binary_accuracy: 0.8480\n",
            "Epoch 22/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3791 - binary_accuracy: 0.8538\n",
            "Epoch 23/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3426 - binary_accuracy: 0.8616\n",
            "Epoch 24/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3409 - binary_accuracy: 0.8733\n",
            "Epoch 25/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3436 - binary_accuracy: 0.8713\n",
            "Epoch 26/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3261 - binary_accuracy: 0.8811\n",
            "Epoch 27/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3145 - binary_accuracy: 0.8791\n",
            "Epoch 28/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3240 - binary_accuracy: 0.8850\n",
            "Epoch 29/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.3151 - binary_accuracy: 0.8791\n",
            "Epoch 30/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2998 - binary_accuracy: 0.8986\n",
            "Epoch 31/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2960 - binary_accuracy: 0.8850\n",
            "Epoch 32/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.3180 - binary_accuracy: 0.8772\n",
            "Epoch 33/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2855 - binary_accuracy: 0.8947\n",
            "Epoch 34/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2888 - binary_accuracy: 0.8928\n",
            "Epoch 35/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2716 - binary_accuracy: 0.8947\n",
            "Epoch 36/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2829 - binary_accuracy: 0.8986\n",
            "Epoch 37/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2873 - binary_accuracy: 0.8908\n",
            "Epoch 38/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2722 - binary_accuracy: 0.8928\n",
            "Epoch 39/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2577 - binary_accuracy: 0.9045\n",
            "Epoch 40/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2677 - binary_accuracy: 0.8986\n",
            "Epoch 41/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2834 - binary_accuracy: 0.8928\n",
            "Epoch 42/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2715 - binary_accuracy: 0.8908\n",
            "Epoch 43/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2676 - binary_accuracy: 0.8908\n",
            "Epoch 44/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2628 - binary_accuracy: 0.8986\n",
            "Epoch 45/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2699 - binary_accuracy: 0.9084\n",
            "Epoch 46/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2618 - binary_accuracy: 0.9006\n",
            "Epoch 47/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2641 - binary_accuracy: 0.8947\n",
            "Epoch 48/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2647 - binary_accuracy: 0.9045\n",
            "Epoch 49/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2779 - binary_accuracy: 0.8986\n",
            "Epoch 50/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2499 - binary_accuracy: 0.8986\n",
            "Epoch 51/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2654 - binary_accuracy: 0.8908\n",
            "Epoch 52/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2523 - binary_accuracy: 0.9064\n",
            "Epoch 53/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2409 - binary_accuracy: 0.8986\n",
            "Epoch 54/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2563 - binary_accuracy: 0.9045\n",
            "Epoch 55/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2586 - binary_accuracy: 0.9064\n",
            "Epoch 56/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2513 - binary_accuracy: 0.9123\n",
            "Epoch 57/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2513 - binary_accuracy: 0.8986\n",
            "Epoch 58/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2539 - binary_accuracy: 0.8986\n",
            "Epoch 59/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2408 - binary_accuracy: 0.9084\n",
            "Epoch 60/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2432 - binary_accuracy: 0.9064\n",
            "Epoch 61/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2484 - binary_accuracy: 0.9103\n",
            "Epoch 62/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2485 - binary_accuracy: 0.9084\n",
            "Epoch 63/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2414 - binary_accuracy: 0.8986\n",
            "Epoch 64/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2421 - binary_accuracy: 0.9123\n",
            "Epoch 65/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2515 - binary_accuracy: 0.9084\n",
            "Epoch 66/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2334 - binary_accuracy: 0.9123\n",
            "Epoch 67/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2554 - binary_accuracy: 0.9064\n",
            "Epoch 68/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2445 - binary_accuracy: 0.9084\n",
            "Epoch 69/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2418 - binary_accuracy: 0.9064\n",
            "Epoch 70/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2181 - binary_accuracy: 0.9201\n",
            "Epoch 71/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2240 - binary_accuracy: 0.9181\n",
            "Epoch 72/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2253 - binary_accuracy: 0.9103\n",
            "Epoch 73/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2314 - binary_accuracy: 0.9142\n",
            "Epoch 74/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2303 - binary_accuracy: 0.9103\n",
            "Epoch 75/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2192 - binary_accuracy: 0.9201\n",
            "Epoch 76/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2364 - binary_accuracy: 0.9084\n",
            "Epoch 77/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2413 - binary_accuracy: 0.9201\n",
            "Epoch 78/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2421 - binary_accuracy: 0.9103\n",
            "Epoch 79/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2605 - binary_accuracy: 0.9103\n",
            "Epoch 80/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2421 - binary_accuracy: 0.9142\n",
            "Epoch 81/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2342 - binary_accuracy: 0.9123\n",
            "Epoch 82/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2423 - binary_accuracy: 0.9142\n",
            "Epoch 83/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2088 - binary_accuracy: 0.9181\n",
            "Epoch 84/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2503 - binary_accuracy: 0.9045\n",
            "Epoch 85/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2174 - binary_accuracy: 0.9162\n",
            "Epoch 86/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2292 - binary_accuracy: 0.9103\n",
            "Epoch 87/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2661 - binary_accuracy: 0.9025\n",
            "Epoch 88/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2255 - binary_accuracy: 0.9123\n",
            "Epoch 89/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2351 - binary_accuracy: 0.9181\n",
            "Epoch 90/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2289 - binary_accuracy: 0.9181\n",
            "Epoch 91/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2192 - binary_accuracy: 0.9162\n",
            "Epoch 92/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2199 - binary_accuracy: 0.9123\n",
            "Epoch 93/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2261 - binary_accuracy: 0.9142\n",
            "Epoch 94/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2103 - binary_accuracy: 0.9240\n",
            "Epoch 95/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2275 - binary_accuracy: 0.9103\n",
            "Epoch 96/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2406 - binary_accuracy: 0.9240\n",
            "Epoch 97/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2161 - binary_accuracy: 0.9142\n",
            "Epoch 98/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2175 - binary_accuracy: 0.9064\n",
            "Epoch 99/100\n",
            "52/52 [==============================] - 0s 1ms/step - loss: 0.2233 - binary_accuracy: 0.9201\n",
            "Epoch 100/100\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.2061 - binary_accuracy: 0.9162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuQ364C0Zd15",
        "outputId": "f262a5f1-7892-48e4-afa5-0792773fa908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "resultados.mean()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8559210526315789"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMYJ5C_TzECe",
        "outputId": "843d265f-0645-4d4e-8072-335f3d9b538f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "resultados.std()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.051840268468662916"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b14Yn1COchp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
