{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classificacao_binaria_breast_cancer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNkLBomds4f+kb3iQOMjB50",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itimes-digital/deep-learning-estudo/blob/main/classificacao_binaria_simples_breast_cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ip00_xXzIcE"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaRAemgJMDAN",
        "outputId": "34556179-631a-4d3f-d8cb-23dda898e4e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "previsores = pd.read_csv(\"https://raw.githubusercontent.com/itimes-digital/deep-learning-estudo/main/dataset/entradas_breast.csv\", sep=\",\")\n",
        "previsores.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave_points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave_points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave_points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1095.0000</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8589.0</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3398.0</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>186.0000</td>\n",
              "      <td>275.0000</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4585.0</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>243.0000</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1156.0000</td>\n",
              "      <td>3445.0</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>173.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>198.0000</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5438.0</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>205.0000</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    radius_mean   texture_mean  ...   symmetry_worst   fractal_dimension_worst\n",
              "0         17.99          10.38  ...           0.4601                   0.11890\n",
              "1         20.57          17.77  ...         275.0000                   0.08902\n",
              "2         19.69          21.25  ...           0.3613                   0.08758\n",
              "3         11.42          20.38  ...           0.6638                 173.00000\n",
              "4         20.29          14.34  ...           0.2364                   0.07678\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zGlSapRMLyK",
        "outputId": "f72186de-e44c-4fa5-da04-dfb01dc05310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        }
      },
      "source": [
        "previsores.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 30 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0    radius_mean              569 non-null    float64\n",
            " 1    texture_mean             569 non-null    float64\n",
            " 2    perimeter_mean           569 non-null    float64\n",
            " 3    area_mean                569 non-null    float64\n",
            " 4    smoothness_mean          569 non-null    float64\n",
            " 5    compactness_mean         569 non-null    float64\n",
            " 6    concavity_mean           569 non-null    float64\n",
            " 7   concave_points_mean       569 non-null    float64\n",
            " 8    symmetry_mean            569 non-null    float64\n",
            " 9    fractal_dimension_mean   569 non-null    float64\n",
            " 10   radius_se                569 non-null    float64\n",
            " 11   texture_se               569 non-null    float64\n",
            " 12   perimeter_se             569 non-null    float64\n",
            " 13   area_se                  569 non-null    float64\n",
            " 14   smoothness_se            569 non-null    float64\n",
            " 15   compactness_se           569 non-null    float64\n",
            " 16   concavity_se             569 non-null    float64\n",
            " 17   concave_points_se        569 non-null    float64\n",
            " 18   symmetry_se              569 non-null    float64\n",
            " 19   fractal_dimension_se     569 non-null    float64\n",
            " 20   radius_worst             569 non-null    float64\n",
            " 21   texture_worst            569 non-null    float64\n",
            " 22   perimeter_worst          569 non-null    float64\n",
            " 23   area_worst               569 non-null    float64\n",
            " 24   smoothness_worst         569 non-null    float64\n",
            " 25   compactness_worst        569 non-null    float64\n",
            " 26   concavity_worst          569 non-null    float64\n",
            " 27   concave_points_worst     569 non-null    float64\n",
            " 28   symmetry_worst           569 non-null    float64\n",
            " 29   fractal_dimension_worst  569 non-null    float64\n",
            "dtypes: float64(30)\n",
            "memory usage: 133.5 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3u7mliUMish",
        "outputId": "0f249430-4762-433e-c9fe-d4000243bc01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "classe = pd.read_csv(\"https://raw.githubusercontent.com/itimes-digital/deep-learning-estudo/main/dataset/saidas_breast.csv\")\n",
        "classe.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype\n",
            "---  ------  --------------  -----\n",
            " 0   0       569 non-null    int64\n",
            "dtypes: int64(1)\n",
            "memory usage: 4.6 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlNaqOa-MdOC",
        "outputId": "2efabc2e-fb16-4652-a135-9ef42c0dcef0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "classe.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0\n",
              "0  0\n",
              "1  0\n",
              "2  0\n",
              "3  0\n",
              "4  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxUoFl1MciQa"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# previsores_treinamento = x_train\n",
        "# previsores_teste = x_test\n",
        "# classe_treinamento = y_train\n",
        "# classe_teste = y_test\n",
        "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores, \n",
        "                                                                                              classe, \n",
        "                                                                                              test_size = 0.25)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpMUF67KdXBT",
        "outputId": "7df7bc4d-6f7b-4703-80c5-6d9b067d580f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        }
      },
      "source": [
        "previsores_treinamento.info()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 426 entries, 156 to 193\n",
            "Data columns (total 30 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0    radius_mean              426 non-null    float64\n",
            " 1    texture_mean             426 non-null    float64\n",
            " 2    perimeter_mean           426 non-null    float64\n",
            " 3    area_mean                426 non-null    float64\n",
            " 4    smoothness_mean          426 non-null    float64\n",
            " 5    compactness_mean         426 non-null    float64\n",
            " 6    concavity_mean           426 non-null    float64\n",
            " 7   concave_points_mean       426 non-null    float64\n",
            " 8    symmetry_mean            426 non-null    float64\n",
            " 9    fractal_dimension_mean   426 non-null    float64\n",
            " 10   radius_se                426 non-null    float64\n",
            " 11   texture_se               426 non-null    float64\n",
            " 12   perimeter_se             426 non-null    float64\n",
            " 13   area_se                  426 non-null    float64\n",
            " 14   smoothness_se            426 non-null    float64\n",
            " 15   compactness_se           426 non-null    float64\n",
            " 16   concavity_se             426 non-null    float64\n",
            " 17   concave_points_se        426 non-null    float64\n",
            " 18   symmetry_se              426 non-null    float64\n",
            " 19   fractal_dimension_se     426 non-null    float64\n",
            " 20   radius_worst             426 non-null    float64\n",
            " 21   texture_worst            426 non-null    float64\n",
            " 22   perimeter_worst          426 non-null    float64\n",
            " 23   area_worst               426 non-null    float64\n",
            " 24   smoothness_worst         426 non-null    float64\n",
            " 25   compactness_worst        426 non-null    float64\n",
            " 26   concavity_worst          426 non-null    float64\n",
            " 27   concave_points_worst     426 non-null    float64\n",
            " 28   symmetry_worst           426 non-null    float64\n",
            " 29   fractal_dimension_worst  426 non-null    float64\n",
            "dtypes: float64(30)\n",
            "memory usage: 103.2 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm6KvUM3dZl3",
        "outputId": "9b4ad3d3-8020-4a7d-8d78-8144e705df8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        }
      },
      "source": [
        "previsores_teste.info()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 143 entries, 307 to 424\n",
            "Data columns (total 30 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0    radius_mean              143 non-null    float64\n",
            " 1    texture_mean             143 non-null    float64\n",
            " 2    perimeter_mean           143 non-null    float64\n",
            " 3    area_mean                143 non-null    float64\n",
            " 4    smoothness_mean          143 non-null    float64\n",
            " 5    compactness_mean         143 non-null    float64\n",
            " 6    concavity_mean           143 non-null    float64\n",
            " 7   concave_points_mean       143 non-null    float64\n",
            " 8    symmetry_mean            143 non-null    float64\n",
            " 9    fractal_dimension_mean   143 non-null    float64\n",
            " 10   radius_se                143 non-null    float64\n",
            " 11   texture_se               143 non-null    float64\n",
            " 12   perimeter_se             143 non-null    float64\n",
            " 13   area_se                  143 non-null    float64\n",
            " 14   smoothness_se            143 non-null    float64\n",
            " 15   compactness_se           143 non-null    float64\n",
            " 16   concavity_se             143 non-null    float64\n",
            " 17   concave_points_se        143 non-null    float64\n",
            " 18   symmetry_se              143 non-null    float64\n",
            " 19   fractal_dimension_se     143 non-null    float64\n",
            " 20   radius_worst             143 non-null    float64\n",
            " 21   texture_worst            143 non-null    float64\n",
            " 22   perimeter_worst          143 non-null    float64\n",
            " 23   area_worst               143 non-null    float64\n",
            " 24   smoothness_worst         143 non-null    float64\n",
            " 25   compactness_worst        143 non-null    float64\n",
            " 26   concavity_worst          143 non-null    float64\n",
            " 27   concave_points_worst     143 non-null    float64\n",
            " 28   symmetry_worst           143 non-null    float64\n",
            " 29   fractal_dimension_worst  143 non-null    float64\n",
            "dtypes: float64(30)\n",
            "memory usage: 34.6 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUik7a1tdiKv",
        "outputId": "ad88c09a-0270-4f09-95eb-24f9bf011f1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "classe_treinamento.info()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 426 entries, 156 to 193\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype\n",
            "---  ------  --------------  -----\n",
            " 0   0       426 non-null    int64\n",
            "dtypes: int64(1)\n",
            "memory usage: 6.7 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaoe6MiZdl5_",
        "outputId": "fd8a2163-9257-4459-b513-756dac1f93c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "classe_teste.info()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 143 entries, 307 to 424\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype\n",
            "---  ------  --------------  -----\n",
            " 0   0       143 non-null    int64\n",
            "dtypes: int64(1)\n",
            "memory usage: 2.2 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g6n8WsidoT3"
      },
      "source": [
        "import keras"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RexXf9H_eAV8"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtgFqY6pfIcE"
      },
      "source": [
        "Definição do números de neurônios por camada:\n",
        "\n",
        "(numero de entrada + numero de saídas esperada) / 2 = número de units na camada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O4W7keffmao",
        "outputId": "899f7543-903a-44ce-e9c5-716aacee0164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Medida base para definir a quantidade de neurônios na camada.\n",
        "# Como a classificação é binária, a resposta será 0 ou 1, portanto, uma saída.\n",
        "quantSaidaEsperada = 1\n",
        "units = (previsores.columns.size + quantSaidaEsperada) / 2\n",
        "units = np.round(units)\n",
        "units"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjZEHAGLek7e"
      },
      "source": [
        "# input_dim define a quantidade de neurônios para a camada de entrada.\n",
        "classificador = Sequential()\n",
        "classificador.add(Dense(units=units, # define a quantidade de neurônios da primeira camada oculta \n",
        "                        activation='relu', \n",
        "                        kernel_initializer='random_uniform', \n",
        "                        input_dim=30))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFJRJl67iNxZ"
      },
      "source": [
        "# Definindo a camada de saída\n",
        "# Como é um classificador binário para 0 ou 1\n",
        "# A quantidade de neurônio é 1\n",
        "classificador.add(Dense(units=1, activation=\"sigmoid\"))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJd_5c4Ii5ol",
        "outputId": "431f6cb0-9854-4ad7-d279-86f9edc8de22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# para classificação binária deve usar binary_crossentropy\n",
        "# para classificação com mais de duas classes deve usar categorical_crossentropy\n",
        "classificador.compile(optimizer='adam', \n",
        "                      loss='binary_crossentropy',\n",
        "                      metrics=['binary_accuracy'])\n",
        "classificador.fit(previsores_treinamento, \n",
        "                  classe_treinamento,\n",
        "                  batch_size=10, # Atualização de pesos a cada 10 registros por épocas\n",
        "                  epochs=100)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 11.8009 - binary_accuracy: 0.5587\n",
            "Epoch 2/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 2.1679 - binary_accuracy: 0.7441\n",
            "Epoch 3/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 1.3337 - binary_accuracy: 0.7770\n",
            "Epoch 4/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.9127 - binary_accuracy: 0.8099\n",
            "Epoch 5/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.8250 - binary_accuracy: 0.8052\n",
            "Epoch 6/100\n",
            "43/43 [==============================] - 0s 982us/step - loss: 0.6074 - binary_accuracy: 0.8404\n",
            "Epoch 7/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5030 - binary_accuracy: 0.8568\n",
            "Epoch 8/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.6189 - binary_accuracy: 0.8404\n",
            "Epoch 9/100\n",
            "43/43 [==============================] - 0s 997us/step - loss: 0.7898 - binary_accuracy: 0.8216\n",
            "Epoch 10/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3814 - binary_accuracy: 0.8756\n",
            "Epoch 11/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3050 - binary_accuracy: 0.8944\n",
            "Epoch 12/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4139 - binary_accuracy: 0.8850\n",
            "Epoch 13/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2746 - binary_accuracy: 0.8991\n",
            "Epoch 14/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2764 - binary_accuracy: 0.9014\n",
            "Epoch 15/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3640 - binary_accuracy: 0.8967\n",
            "Epoch 16/100\n",
            "43/43 [==============================] - 0s 982us/step - loss: 0.2866 - binary_accuracy: 0.8991\n",
            "Epoch 17/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5253 - binary_accuracy: 0.8592\n",
            "Epoch 18/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4965 - binary_accuracy: 0.8615\n",
            "Epoch 19/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3270 - binary_accuracy: 0.8850\n",
            "Epoch 20/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3208 - binary_accuracy: 0.8826\n",
            "Epoch 21/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2547 - binary_accuracy: 0.9131\n",
            "Epoch 22/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2492 - binary_accuracy: 0.9108\n",
            "Epoch 23/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2500 - binary_accuracy: 0.9131\n",
            "Epoch 24/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3771 - binary_accuracy: 0.8826\n",
            "Epoch 25/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2406 - binary_accuracy: 0.9178\n",
            "Epoch 26/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2446 - binary_accuracy: 0.9085\n",
            "Epoch 27/100\n",
            "43/43 [==============================] - 0s 963us/step - loss: 0.2505 - binary_accuracy: 0.9108\n",
            "Epoch 28/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4431 - binary_accuracy: 0.8709\n",
            "Epoch 29/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2864 - binary_accuracy: 0.9178\n",
            "Epoch 30/100\n",
            "43/43 [==============================] - 0s 989us/step - loss: 0.4095 - binary_accuracy: 0.8756\n",
            "Epoch 31/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5091 - binary_accuracy: 0.8850\n",
            "Epoch 32/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4379 - binary_accuracy: 0.8967\n",
            "Epoch 33/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3196 - binary_accuracy: 0.9038\n",
            "Epoch 34/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3205 - binary_accuracy: 0.9272\n",
            "Epoch 35/100\n",
            "43/43 [==============================] - 0s 982us/step - loss: 0.3435 - binary_accuracy: 0.9131\n",
            "Epoch 36/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2734 - binary_accuracy: 0.9178\n",
            "Epoch 37/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3197 - binary_accuracy: 0.8967\n",
            "Epoch 38/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2740 - binary_accuracy: 0.9085\n",
            "Epoch 39/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3210 - binary_accuracy: 0.8920\n",
            "Epoch 40/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1664 - binary_accuracy: 0.9343\n",
            "Epoch 41/100\n",
            "43/43 [==============================] - 0s 992us/step - loss: 0.2558 - binary_accuracy: 0.9131\n",
            "Epoch 42/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3018 - binary_accuracy: 0.9155\n",
            "Epoch 43/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2262 - binary_accuracy: 0.9202\n",
            "Epoch 44/100\n",
            "43/43 [==============================] - 0s 996us/step - loss: 0.3853 - binary_accuracy: 0.9014\n",
            "Epoch 45/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2328 - binary_accuracy: 0.9085\n",
            "Epoch 46/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2742 - binary_accuracy: 0.9131\n",
            "Epoch 47/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3187 - binary_accuracy: 0.9061\n",
            "Epoch 48/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3576 - binary_accuracy: 0.9178\n",
            "Epoch 49/100\n",
            "43/43 [==============================] - 0s 995us/step - loss: 0.2999 - binary_accuracy: 0.9202\n",
            "Epoch 50/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3038 - binary_accuracy: 0.9061\n",
            "Epoch 51/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.6220 - binary_accuracy: 0.8638\n",
            "Epoch 52/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4473 - binary_accuracy: 0.8873\n",
            "Epoch 53/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5913 - binary_accuracy: 0.8662\n",
            "Epoch 54/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3233 - binary_accuracy: 0.9108\n",
            "Epoch 55/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5204 - binary_accuracy: 0.9038\n",
            "Epoch 56/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2043 - binary_accuracy: 0.9296\n",
            "Epoch 57/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2910 - binary_accuracy: 0.9249\n",
            "Epoch 58/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1979 - binary_accuracy: 0.9413\n",
            "Epoch 59/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5441 - binary_accuracy: 0.8826\n",
            "Epoch 60/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3877 - binary_accuracy: 0.9108\n",
            "Epoch 61/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4787 - binary_accuracy: 0.8897\n",
            "Epoch 62/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1968 - binary_accuracy: 0.9272\n",
            "Epoch 63/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1774 - binary_accuracy: 0.9319\n",
            "Epoch 64/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1919 - binary_accuracy: 0.9437\n",
            "Epoch 65/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2146 - binary_accuracy: 0.9413\n",
            "Epoch 66/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1647 - binary_accuracy: 0.9531\n",
            "Epoch 67/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2631 - binary_accuracy: 0.9155\n",
            "Epoch 68/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1743 - binary_accuracy: 0.9460\n",
            "Epoch 69/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2751 - binary_accuracy: 0.9249\n",
            "Epoch 70/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.4046 - binary_accuracy: 0.9061\n",
            "Epoch 71/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3360 - binary_accuracy: 0.9108\n",
            "Epoch 72/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2650 - binary_accuracy: 0.9202\n",
            "Epoch 73/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3873 - binary_accuracy: 0.8944\n",
            "Epoch 74/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3464 - binary_accuracy: 0.9061\n",
            "Epoch 75/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2540 - binary_accuracy: 0.9272\n",
            "Epoch 76/100\n",
            "43/43 [==============================] - 0s 982us/step - loss: 0.4282 - binary_accuracy: 0.9038\n",
            "Epoch 77/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5211 - binary_accuracy: 0.9061\n",
            "Epoch 78/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3365 - binary_accuracy: 0.9085\n",
            "Epoch 79/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2396 - binary_accuracy: 0.9296\n",
            "Epoch 80/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2207 - binary_accuracy: 0.9366\n",
            "Epoch 81/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.5119 - binary_accuracy: 0.8850\n",
            "Epoch 82/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1567 - binary_accuracy: 0.9390\n",
            "Epoch 83/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2141 - binary_accuracy: 0.9249\n",
            "Epoch 84/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3138 - binary_accuracy: 0.9131\n",
            "Epoch 85/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2904 - binary_accuracy: 0.9202\n",
            "Epoch 86/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2686 - binary_accuracy: 0.9319\n",
            "Epoch 87/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1862 - binary_accuracy: 0.9390\n",
            "Epoch 88/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.3244 - binary_accuracy: 0.9014\n",
            "Epoch 89/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2408 - binary_accuracy: 0.9343\n",
            "Epoch 90/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1966 - binary_accuracy: 0.9343\n",
            "Epoch 91/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2591 - binary_accuracy: 0.9202\n",
            "Epoch 92/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1404 - binary_accuracy: 0.9554\n",
            "Epoch 93/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2580 - binary_accuracy: 0.9366\n",
            "Epoch 94/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2085 - binary_accuracy: 0.9249\n",
            "Epoch 95/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1978 - binary_accuracy: 0.9413\n",
            "Epoch 96/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2589 - binary_accuracy: 0.9178\n",
            "Epoch 97/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2461 - binary_accuracy: 0.9225\n",
            "Epoch 98/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1866 - binary_accuracy: 0.9390\n",
            "Epoch 99/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.1994 - binary_accuracy: 0.9343\n",
            "Epoch 100/100\n",
            "43/43 [==============================] - 0s 1ms/step - loss: 0.2392 - binary_accuracy: 0.9178\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8f5312f860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHdpaZ2CmudR"
      },
      "source": [
        "previsoes = classificador.predict(previsores_teste)\n",
        "previsoes = (previsoes > 0.5)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4Qj3JCCM7PV",
        "outputId": "ad1cfc31-bfc1-4998-b659-46ad22db7379",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "previsoes"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfkvCbXaNlD8"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl1L_rYSNvLB",
        "outputId": "38a717b2-9e50-4e1b-d0ea-cc5f92e75fa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "precisao = accuracy_score(classe_teste, previsoes)\n",
        "precisao"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8321678321678322"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLbper6dN1XC",
        "outputId": "11169798-f85f-4eb6-8677-bd61800505c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "matriz_confusao = confusion_matrix(classe_teste, previsoes)\n",
        "matriz_confusao"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[37, 18],\n",
              "       [ 6, 82]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8hojJVcOBMJ",
        "outputId": "296af7c6-f3b3-4b77-8141-1619ed04b9b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Usando o Keras\n",
        "resultado = classificador.evaluate(previsores_teste, classe_teste)\n",
        "resultado"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 2ms/step - loss: 0.6628 - binary_accuracy: 0.8322\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6627684235572815, 0.8321678042411804]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b14Yn1COchp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
